{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a10953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "os.chdir(par_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac82c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vae_earlystopping import EarlyStopping\n",
    "from model.m2_mse import MSEcVAE\n",
    "from loss.l2_mse import l2_mse\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iteration 1/20] Seed: 19\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 4 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 4 out of 40\n",
      "EarlyStopping counter: 5 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 4 out of 40\n",
      "EarlyStopping counter: 5 out of 40\n",
      "EarlyStopping counter: 1 out of 40\n",
      "EarlyStopping counter: 2 out of 40\n",
      "EarlyStopping counter: 3 out of 40\n",
      "EarlyStopping counter: 4 out of 40\n",
      "EarlyStopping counter: 5 out of 40\n",
      "EarlyStopping counter: 6 out of 40\n",
      "EarlyStopping counter: 7 out of 40\n",
      "EarlyStopping counter: 8 out of 40\n",
      "EarlyStopping counter: 9 out of 40\n",
      "EarlyStopping counter: 10 out of 40\n",
      "EarlyStopping counter: 11 out of 40\n",
      "EarlyStopping counter: 12 out of 40\n",
      "EarlyStopping counter: 13 out of 40\n",
      "EarlyStopping counter: 14 out of 40\n",
      "EarlyStopping counter: 15 out of 40\n",
      "EarlyStopping counter: 16 out of 40\n",
      "EarlyStopping counter: 17 out of 40\n",
      "EarlyStopping counter: 18 out of 40\n",
      "EarlyStopping counter: 19 out of 40\n",
      "EarlyStopping counter: 20 out of 40\n",
      "EarlyStopping counter: 21 out of 40\n",
      "EarlyStopping counter: 22 out of 40\n",
      "EarlyStopping counter: 23 out of 40\n",
      "EarlyStopping counter: 24 out of 40\n",
      "EarlyStopping counter: 25 out of 40\n",
      "EarlyStopping counter: 26 out of 40\n",
      "EarlyStopping counter: 27 out of 40\n",
      "EarlyStopping counter: 28 out of 40\n",
      "EarlyStopping counter: 29 out of 40\n",
      "EarlyStopping counter: 30 out of 40\n",
      "EarlyStopping counter: 31 out of 40\n",
      "EarlyStopping counter: 32 out of 40\n",
      "EarlyStopping counter: 33 out of 40\n",
      "EarlyStopping counter: 34 out of 40\n",
      "EarlyStopping counter: 35 out of 40\n",
      "EarlyStopping counter: 36 out of 40\n",
      "EarlyStopping counter: 37 out of 40\n",
      "EarlyStopping counter: 38 out of 40\n",
      "EarlyStopping counter: 39 out of 40\n",
      "EarlyStopping counter: 40 out of 40\n",
      "Restored best model with loss: 0.139205\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'R2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Case 2: Without Reaction\u001b[39;00m\n\u001b[32m     83\u001b[39m     r2 = train_and_evaluate(\u001b[33m'\u001b[39m\u001b[33m./data/pre_re_change_temp_logconst.npy\u001b[39m\u001b[33m'\u001b[39m, x_data, seed)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mR2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.append(\u001b[38;5;28mfloat\u001b[39m(r2))\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m R2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'R2'"
     ]
    }
   ],
   "source": [
    "# 결과 저장용\n",
    "results = {\n",
    "    \"R2_\": [],\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_and_evaluate(c_path, x_data, seed):\n",
    "    \"\"\"\n",
    "    특정 조건 데이터(c_path)를 받아 BCE+MSE 결합 모델의 R2 Score를 반환하는 함수\n",
    "    \"\"\"\n",
    "    c_data = np.load(c_path)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    x_train, x_temp, c_train, c_temp = train_test_split(x_data, c_data, random_state=seed, test_size=0.4)\n",
    "    x_val, x_test, c_val, c_test = train_test_split(x_temp, c_temp, random_state=seed, test_size=0.5)\n",
    "    \n",
    "    # 스케일링\n",
    "    x_scaler, c_scaler = MinMaxScaler(), MinMaxScaler()\n",
    "    x_train = x_scaler.fit_transform(x_train)\n",
    "    c_train = c_scaler.fit_transform(c_train)\n",
    "    x_val, x_test = x_scaler.transform(x_val), x_scaler.transform(x_test)\n",
    "    c_val, c_test = c_scaler.transform(c_val), c_scaler.transform(c_test)\n",
    "    \n",
    "    # Loader 생성\n",
    "    t_loader = DataLoader(TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(c_train)), batch_size=64, shuffle=True)\n",
    "    v_loader = DataLoader(TensorDataset(torch.FloatTensor(x_val), torch.FloatTensor(c_val)), batch_size=64)\n",
    "    test_loader = DataLoader(TensorDataset(torch.FloatTensor(x_test), torch.FloatTensor(c_test)), batch_size=64)\n",
    "    \n",
    "    x_dim, c_dim = x_train.shape[1], c_train.shape[1]\n",
    "\n",
    "    # --- MSE 모델 학습 ---\n",
    "    model_mse = MSEcVAE(x_dim, c_dim, z_dim=8).to(device)\n",
    "    opt_mse = optim.Adam(model_mse.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    es_mse = EarlyStopping(patience=40, min_delta=1e-9)\n",
    "    \n",
    "    for epoch in range(1, 801):\n",
    "        model_mse.train()\n",
    "        for x, c in t_loader:\n",
    "            x, c = x.to(device), c.to(device)\n",
    "            opt_mse.zero_grad()\n",
    "            xh, mu, logvar = model_mse(x, c)\n",
    "            loss = l2_mse(xh, x, mu, logvar)['loss']\n",
    "            loss.backward(); opt_mse.step()\n",
    "            \n",
    "        model_mse.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for vx, vc in v_loader:\n",
    "                vx, vc = vx.to(device), vc.to(device)\n",
    "                xh, vm, vv = model_mse(vx, vc)\n",
    "                val_loss += l2_mse(xh, vx, vm, vv)['loss'].item()\n",
    "        if es_mse(val_loss/len(v_loader), model_mse): break\n",
    "        \n",
    "    es_mse.load_best_model(model_mse)\n",
    "\n",
    "    # --- 3. 최종 평가 (BCE_MSE 가중합) ---\n",
    "    model_mse.eval()\n",
    "    mse_preds, x_true = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xt, ct in test_loader:\n",
    "            xt, ct = xt.to(device), ct.to(device)\n",
    "            m_pred, _, _ = model_mse(xt, ct)\n",
    "            mse_preds.append(m_pred.cpu().numpy())\n",
    "            x_true.append(xt.cpu().numpy())\n",
    "            \n",
    "    x_hat = x_scaler.inverse_transform(np.vstack(mse_preds))\n",
    "    x_true = x_scaler.inverse_transform(np.vstack(x_true))\n",
    "    \n",
    "    # Soft weighting 적용\n",
    "    return r2_score(x_true.flatten(), x_hat.flatten())\n",
    "\n",
    "# --- 메인 실험 루프 ---\n",
    "x_data = np.load('./data/metal.npy')\n",
    "seeds = np.random.randint(1, 100, size=20)\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"\\n[Iteration {i+1}/20] Seed: {seed}\")\n",
    "    \n",
    "    \n",
    "    # Case 2: Without Reaction\n",
    "    r2 = train_and_evaluate('./data/pre_re_change_temp_logconst.npy', x_data, seed)\n",
    "    results[\"R2_\"].append(float(r2))\n",
    "    \n",
    "    print(f\" R2: {r2:.4f}\")\n",
    "\n",
    "# 결과 저장\n",
    "with open(\"./compare_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b672fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./results_regression_logreaction_constant.json\"\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
